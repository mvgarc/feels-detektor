# Feelsâ€‘Detektor  

Detector de emociones faciales en tiempo real usando Python, OpenCV y una red neuronal.  

##  QuÃ© hace ?

- Usa la cÃ¡mara web para capturar video.  
- Detecta rostros con un clasificador Haar cascade.  
- Preprocesa el rostro a escala de grises y 48Ã—48 px.  
- Utiliza un modelo entrenado (formato `.json` + `.h5`) para predecir la emociÃ³n:  
  - angry, disgust, fear, happy, neutral, sad, surprise  
- Muestra, en una ventana redimensionable, el video con rectÃ¡ngulos en los rostros y la emociÃ³n reconocida encima.  
- Permite cerrar la ventana presionando `q` o con la X correctamente.  

## ğŸš€ CaracterÃ­sticas principales  

- Detector en **tiempo real** usando la webcam  
- Compatible con CPU (no requiere GPU)  
- Ventana redimensionable (`WINDOW_NORMAL`) y configurable en tamaÃ±o  
- Procesamiento de video optimizado: analiza solo cada N frames para reducir carga  
- NormalizaciÃ³n de imÃ¡genes, soporte para mÃºltiples rostros  

## ğŸ“ Estructura del repositorio  
```bash
feels-detektor/
â”‚
â”œâ”€â”€ emotiondetector.json # Arquitectura del modelo
â”œâ”€â”€ emotiondetector.h5 # Pesos del modelo entrenado
â”œâ”€â”€ detector_de_emociones.py # Script principal para detecciÃ³n en tiempo real
â”œâ”€â”€ README.md # Este archivo
â””â”€â”€ (otros archivos de proyectoâ€¦)

```


## ğŸ§° Requisitos / Dependencias  

- Python 3.10 (recomendado)  
- OpenCV (`opencv-python`)  
- NumPy  
- TensorFlow / Keras  

Para instalarlas fÃ¡cilmente, activa tu entorno virtual y luego:

```bash
pip install opencv-python numpy tensorflow keras
```

ğŸ“¥ CÃ³mo ejecutar

Clona este repositorio:
```bash
git clone https://github.com/mvgarc/feels-detektor.git
cd feels-detektor
```
AsegÃºrate de usar Python 3.10 y tener un entorno virtual activado.

Instala las dependencias (ver secciÃ³n anterior).

Ejecuta el script principal:

```bash
python detector_de_emociones.py
```

Se abrirÃ¡ una ventana con la cÃ¡mara. Presiona q o cierra la ventana para salir.

ğŸ”§ CÃ³mo entrenar / reentrenar el modelo

Si quieres mejorar la precisiÃ³n â€” especialmente para clases como â€œsadâ€ o â€œangryâ€ â€” te recomiendo:

Preparar un dataset balanceado con suficientes imÃ¡genes por emociÃ³n; todas en 48Ã—48 px en escala de grises.

Aplicar Data Augmentation para ampliar el dataset.

Usar tu propio script de entrenamiento (por ejemplo con Keras), luego generar nuevos archivos emotiondetector.json + emotiondetector.h5.

Reemplazar los archivos en este repositorio por los nuevos.

ğŸ“ Licencia

Este proyecto estÃ¡ bajo licencia MIT â€” eres libre de usar, modificar y distribuir el cÃ³digo como desees.

âœ¨ Agradecimientos / Referencias

Basado en tÃ©cnicas comunes de detecciÃ³n facial con Haar cascade + redes neuronales para reconocimiento de emociones.

Inspirado en mÃºltiples proyectos de visiÃ³n por computadora usando Python + OpenCV.